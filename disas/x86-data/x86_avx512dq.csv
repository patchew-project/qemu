"Instruction","Opcode","Valid 64-bit","Valid 32-bit","Valid 16-bit","Feature Flags","Operand 1","Operand 2","Operand 3","Operand 4","Tuple Type","Description"
"KADDB k1, k2, k3","VEX.L1.66.0F.W0 4A /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","VEX.vvvv (r)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","","","Add 8 bits masks in k2 and k3 and place result in k1."
"KADDW k1, k2, k3","VEX.L1.0F.W0 4A /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","VEX.vvvv (r)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","","","Add 16 bits masks in k2 and k3 and place result in k1."
"KANDB k1, k2, k3","VEX.L1.66.0F.W0 41 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","VEX.vvvv (r)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","","","Bitwise AND 8 bits masks k2 and k3 and place result in k1."
"KANDNB k1, k2, k3","VEX.L1.66.0F.W0 42 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","VEX.vvvv (r)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","","","Bitwise AND NOT 8 bits masks k1 and k2 and place result in k1."
"KMOVB k1, k2/m8","VEX.L0.66.0F.W0 90 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","","Move 8 bits mask from k2/m8 and store the result in k1."
"KMOVB m8, k1","VEX.L0.66.0F.W0 91 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:r/m (w, ModRM:[7:6] must not be 11b)","ModRM:reg (r)","","","","Move 8 bits mask from k1 and store the result in m8."
"KMOVB k1, rw","VEX.L0.66.0F.W0 92 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","","","","Move 8 bits mask from r to k1."
"KMOVB rw, k1","VEX.L0.66.0F.W0 93 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","","","","Move 8 bits mask from k1 to r."
"KNOTB k1, k2","VEX.L0.66.0F.W0 44 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","","","","Bitwise NOT of 8 bits mask k2."
"KORB k1, k2, k3","VEX.L1.66.0F.W0 45 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","VEX.vvvv (r)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","","","Bitwise OR 8 bits masks k2 and k3 and place result in k1."
"KORTESTB k1, k2","VEX.L0.66.0F.W0 98 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","","","","Bitwise OR 8 bits masks k1 and k2 and update ZF and CF accordingly."
"KSHIFTLB k1, k2, ib","VEX.L0.66.0F3A.W0 32 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","ib","","","Shift left 8 bits in k2 by immediate and write result in k1."
"KSHIFTRB k1, k2, ib","VEX.L0.66.0F3A.W0 30 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","ib","","","Shift right 8 bits in k2 by immediate and write result in k1."
"KTESTB k1, k2","VEX.L0.66.0F.W0 99 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (r)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","","","","Set ZF and CF depending on sign bit AND and ANDN of 8 bits mask register sources."
"KTESTW k1, k2","VEX.L0.0F.W0 99 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (r)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","","","","Set ZF and CF depending on sign bit AND and ANDN of 16 bits mask register sources."
"KXNORB k1, k2, k3","VEX.L1.66.0F.W0 46 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","VEX.vvvv (r)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","","","Bitwise XNOR 8 bits masks k2 and k3 and place result in k1."
"KXORB k1, k2, k3","VEX.L1.66.0F.W0 47 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","VEX.vvvv (r)","ModRM:r/m (r, ModRM:[7:6] must be 11b)","","","Bitwise XOR 8 bits masks k2 and k3 and place result in k1."
"VANDNPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst","EVEX.128.66.0F.W1 55 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical AND NOT of packed double-precision floating-point values in xmm2 and xmm3/m128/m64bcst subject to writemask k1."
"VANDNPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst","EVEX.256.66.0F.W1 55 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical AND NOT of packed double-precision floating-point values in ymm2 and ymm3/m256/m64bcst subject to writemask k1."
"VANDNPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst","EVEX.512.66.0F.W1 55 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical AND NOT of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1."
"VANDNPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst","EVEX.128.0F.W0 55 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical AND of packed single-precision floating-point values in xmm2 and xmm3/m128/m32bcst subject to writemask k1."
"VANDNPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst","EVEX.256.0F.W0 55 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical AND of packed single-precision floating-point values in ymm2 and ymm3/m256/m32bcst subject to writemask k1."
"VANDNPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst","EVEX.512.0F.W0 55 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical AND of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1."
"VANDPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst","EVEX.128.66.0F.W1 54 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical AND of packed double-precision floating-point values in xmm2 and xmm3/m128/m64bcst subject to writemask k1."
"VANDPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst","EVEX.256.66.0F.W1 54 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical AND of packed double-precision floating-point values in ymm2 and ymm3/m256/m64bcst subject to writemask k1."
"VANDPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst","EVEX.512.66.0F.W1 54 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical AND of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1."
"VANDPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst","EVEX.128.0F.W0 54 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical AND of packed single-precision floating-point values in xmm2 and xmm3/m128/m32bcst subject to writemask k1."
"VANDPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst","EVEX.256.0F.W0 54 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical AND of packed single-precision floating-point values in ymm2 and ymm3/m256/m32bcst subject to writemask k1."
"VANDPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst","EVEX.512.0F.W0 54 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical AND of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1."
"VBROADCASTF32X2 ymm1 {k1}{z}, xmm2/m64","EVEX.256.66.0F38.W0 19 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple2","Broadcast two single-precision floating-point elements in xmm2/m64 to locations in ymm1 using writemask k1."
"VBROADCASTF32X2 zmm1 {k1}{z}, xmm2/m64","EVEX.512.66.0F38.W0 19 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple2","Broadcast two single-precision floating-point elements in xmm2/m64 to locations in zmm1 using writemask k1."
"VBROADCASTF32X8 zmm1 {k1}{z}, m256","EVEX.512.66.0F38.W0 1B /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple8","Broadcast 256 bits of 8 single precision floating-point data in mem to locations in zmm1 using writemask k1."
"VBROADCASTF64X2 ymm1 {k1}{z}, m128","EVEX.256.66.0F38.W1 1A /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple2","Broadcast 128 bits of 2 double-precision floating-point data in mem to locations in ymm1 using writemask k1."
"VBROADCASTF64X2 zmm1 {k1}{z}, m128","EVEX.512.66.0F38.W1 1A /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple2","Broadcast 128 bits of 2 double-precision floating-point data in mem to locations in zmm1 using writemask k1."
"VBROADCASTI32X2 xmm1 {k1}{z}, xmm2/m64","EVEX.128.66.0F38.W0 59 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple2","Broadcast two dword elements in source operand to locations in xmm1 subject to writemask k1."
"VBROADCASTI32X2 ymm1 {k1}{z}, xmm2/m64","EVEX.256.66.0F38.W0 59 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple2","Broadcast two dword elements in source operand to locations in ymm1 subject to writemask k1."
"VBROADCASTI32X2 zmm1 {k1}{z}, xmm2/m64","EVEX.512.66.0F38.W0 59 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple2","Broadcast two dword elements in source operand to locations in zmm1 subject to writemask k1."
"VBROADCASTI32X8 zmm1 {k1}{z}, m256","EVEX.512.66.0F38.W0 5B /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple8","Broadcast 256 bits of 8 doubleword integer data in mem to locations in zmm1 using writemask k1."
"VBROADCASTI64X2 ymm1 {k1}{z}, m128","EVEX.256.66.0F38.W1 5A /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple2","Broadcast 128 bits of 2 quadword integer data in mem to locations in ymm1 using writemask k1."
"VBROADCASTI64X2 zmm1 {k1}{z}, m128","EVEX.512.66.0F38.W1 5A /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple2","Broadcast 128 bits of 2 quadword integer data in mem to locations in zmm1 using writemask k1."
"VCVTPD2QQ xmm1 {k1}{z}, xmm2/m128/m64bcst","EVEX.128.66.0F.W1 7B /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert two packed double-precision floating-point values from xmm2/m128/m64bcst to two packed quadword integers in xmm1 with writemask k1."
"VCVTPD2QQ ymm1 {k1}{z}, ymm2/m256/m64bcst","EVEX.256.66.0F.W1 7B /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert four packed double-precision floating-point values from ymm2/m256/m64bcst to four packed quadword integers in ymm1 with writemask k1."
"VCVTPD2QQ zmm1 {k1}{z}, zmm2/m512/m64bcst{er}","EVEX.512.66.0F.W1 7B /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert eight packed double-precision floating-point values from zmm2/m512/m64bcst to eight packed quadword integers in zmm1 with writemask k1."
"VCVTPD2UQQ xmm1 {k1}{z}, xmm2/m128/m64bcst","EVEX.128.66.0F.W1 79 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert two packed double-precision floating-point values from xmm2/mem to two packed unsigned quadword integers in xmm1 with writemask k1."
"VCVTPD2UQQ ymm1 {k1}{z}, ymm2/m256/m64bcst","EVEX.256.66.0F.W1 79 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert fourth packed double-precision floating-point values from ymm2/mem to four packed unsigned quadword integers in ymm1 with writemask k1."
"VCVTPD2UQQ zmm1 {k1}{z}, zmm2/m512/m64bcst{er}","EVEX.512.66.0F.W1 79 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert eight packed double-precision floating-point values from zmm2/mem to eight packed unsigned quadword integers in zmm1 with writemask k1."
"VCVTPS2QQ xmm1 {k1}{z}, xmm2/m64/m32bcst","EVEX.128.66.0F.W0 7B /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Half Vector","Convert two packed single precision floating-point values from xmm2/m64/m32bcst to two packed signed quadword values in xmm1 subject to writemask k1."
"VCVTPS2QQ ymm1 {k1}{z}, xmm2/m128/m32bcst","EVEX.256.66.0F.W0 7B /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Half Vector","Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed signed quadword values in ymm1 subject to writemask k1."
"VCVTPS2QQ zmm1 {k1}{z}, ymm2/m256/m32bcst{er}","EVEX.512.66.0F.W0 7B /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Half Vector","Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed signed quadword values in zmm1 subject to writemask k1."
"VCVTPS2UQQ xmm1 {k1}{z}, xmm2/m64/m32bcst","EVEX.128.66.0F.W0 79 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Half Vector","Convert two packed single precision floating-point values from zmm2/m64/m32bcst to two packed unsigned quadword values in zmm1 subject to writemask k1."
"VCVTPS2UQQ ymm1 {k1}{z}, xmm2/m128/m32bcst","EVEX.256.66.0F.W0 79 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Half Vector","Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed unsigned quadword values in ymm1 subject to writemask k1."
"VCVTPS2UQQ zmm1 {k1}{z}, ymm2/m256/m32bcst{er}","EVEX.512.66.0F.W0 79 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Half Vector","Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed unsigned quadword values in zmm1 subject to writemask k1."
"VCVTQQ2PD xmm1 {k1}{z}, xmm2/m128/m64bcst","EVEX.128.F3.0F.W1 E6 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert two packed quadword integers from xmm2/m128/m64bcst to packed double-precision floating-point values in xmm1 with writemask k1."
"VCVTQQ2PD ymm1 {k1}{z}, ymm2/m256/m64bcst","EVEX.256.F3.0F.W1 E6 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert four packed quadword integers from ymm2/m256/m64bcst to packed double-precision floating-point values in ymm1 with writemask k1."
"VCVTQQ2PD zmm1 {k1}{z}, zmm2/m512/m64bcst{er}","EVEX.512.F3.0F.W1 E6 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert eight packed quadword integers from zmm2/m512/m64bcst to eight packed double-precision floating-point values in zmm1 with writemask k1."
"VCVTQQ2PS xmm1 {k1}{z}, xmm2/m128/m64bcst","EVEX.128.0F.W1 5B /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert two packed quadword integers from xmm2/mem to packed single-precision floating-point values in xmm1 with writemask k1."
"VCVTQQ2PS xmm1 {k1}{z}, ymm2/m256/m64bcst","EVEX.256.0F.W1 5B /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert four packed quadword integers from ymm2/mem to packed single-precision floating-point values in xmm1 with writemask k1."
"VCVTQQ2PS ymm1 {k1}{z}, zmm2/m512/m64bcst{er}","EVEX.512.0F.W1 5B /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert eight packed quadword integers from zmm2/mem to eight packed single-precision floating-point values in ymm1 with writemask k1."
"VCVTTPD2QQ xmm1 {k1}{z}, xmm2/m128/m64bcst","EVEX.128.66.0F.W1 7A /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert two packed double-precision floating-point values from zmm2/m128/m64bcst to two packed quadword integers in zmm1 using truncation with writemask k1."
"VCVTTPD2QQ ymm1 {k1}{z}, ymm2/m256/m64bcst","EVEX.256.66.0F.W1 7A /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert four packed double-precision floating-point values from ymm2/m256/m64bcst to four packed quadword integers in ymm1 using truncation with writemask k1."
"VCVTTPD2QQ zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}","EVEX.512.66.0F.W1 7A /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert eight packed double-precision floating-point values from zmm2/m512 to eight packed quadword integers in zmm1 using truncation with writemask k1."
"VCVTTPD2UQQ xmm1 {k1}{z}, xmm2/m128/m64bcst","EVEX.128.66.0F.W1 78 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert two packed double-precision floating-point values from xmm2/m128/m64bcst to two packed unsigned quadword integers in xmm1 using truncation with writemask k1."
"VCVTTPD2UQQ ymm1 {k1}{z}, ymm2/m256/m64bcst","EVEX.256.66.0F.W1 78 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert four packed double-precision floating-point values from ymm2/m256/m64bcst to four packed unsigned quadword integers in ymm1 using truncation with writemask k1."
"VCVTTPD2UQQ zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}","EVEX.512.66.0F.W1 78 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert eight packed double-precision floating-point values from zmm2/mem to eight packed unsigned quadword integers in zmm1 using truncation with writemask k1."
"VCVTTPS2QQ xmm1 {k1}{z}, xmm2/m64/m32bcst","EVEX.128.66.0F.W0 7A /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Half Vector","Convert two packed single precision floating-point values from xmm2/m64/m32bcst to two packed signed quadword values in xmm1 using truncation subject to writemask k1."
"VCVTTPS2QQ ymm1 {k1}{z}, xmm2/m128/m32bcst","EVEX.256.66.0F.W0 7A /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Half Vector","Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed signed quadword values in ymm1 using truncation subject to writemask k1."
"VCVTTPS2QQ zmm1 {k1}{z}, ymm2/m256/m32bcst{sae}","EVEX.512.66.0F.W0 7A /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Half Vector","Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed signed quadword values in zmm1 using truncation subject to writemask k1."
"VCVTTPS2UQQ xmm1 {k1}{z}, xmm2/m64/m32bcst","EVEX.128.66.0F.W0 78 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Half Vector","Convert two packed single precision floating-point values from xmm2/m64/m32bcst to two packed unsigned quadword values in xmm1 using truncation subject to writemask k1."
"VCVTTPS2UQQ ymm1 {k1}{z}, xmm2/m128/m32bcst","EVEX.256.66.0F.W0 78 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Half Vector","Convert four packed single precision floating-point values from xmm2/m128/m32bcst to four packed unsigned quadword values in ymm1 using truncation subject to writemask k1."
"VCVTTPS2UQQ zmm1 {k1}{z}, ymm2/m256/m32bcst{sae}","EVEX.512.66.0F.W0 78 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Half Vector","Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed unsigned quadword values in zmm1 using truncation subject to writemask k1."
"VCVTUQQ2PD xmm1 {k1}{z}, xmm2/m128/m64bcst","EVEX.128.F3.0F.W1 7A /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert two packed unsigned quadword integers from xmm2/m128/m64bcst to two packed double-precision floating-point values in xmm1 with writemask k1."
"VCVTUQQ2PD ymm1 {k1}{z}, ymm2/m256/m64bcst","EVEX.256.F3.0F.W1 7A /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert four packed unsigned quadword integers from ymm2/m256/m64bcst to packed double-precision floating-point values in ymm1 with writemask k1."
"VCVTUQQ2PD zmm1 {k1}{z}, zmm2/m512/m64bcst{er}","EVEX.512.F3.0F.W1 7A /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert eight packed unsigned quadword integers from zmm2/m512/m64bcst to eight packed double-precision floating-point values in zmm1 with writemask k1."
"VCVTUQQ2PS xmm1 {k1}{z}, xmm2/m128/m64bcst","EVEX.128.F2.0F.W1 7A /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert two packed unsigned quadword integers from xmm2/m128/m64bcst to packed single-precision floating-point values in zmm1 with writemask k1."
"VCVTUQQ2PS xmm1 {k1}{z}, ymm2/m256/m64bcst","EVEX.256.F2.0F.W1 7A /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert four packed unsigned quadword integers from ymm2/m256/m64bcst to packed single-precision floating-point values in xmm1 with writemask k1."
"VCVTUQQ2PS ymm1 {k1}{z}, zmm2/m512/m64bcst{er}","EVEX.512.F2.0F.W1 7A /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","Full Vector","Convert eight packed unsigned quadword integers from zmm2/m512/m64bcst to eight packed single-precision floating-point values in zmm1 with writemask k1."
"VEXTRACTF32X8 ymm/m256{k}{z},zmm,ib","EVEX.512.66.0F3A.W0 1b /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:r/m (w)","ModRM:reg (r)","ib","","Tuple8","Extract 256 bits of packed single precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1."
"VEXTRACTF64X2 xmm/m128{k}{z},ymm,ib","EVEX.256.66.0F3A.W1 19 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:r/m (w)","ModRM:reg (r)","ib","","Tuple2","Extract 128 bits of packed double precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1."
"VEXTRACTF64X2 xmm/m128{k}{z},zmm,ib","EVEX.512.66.0F3A.W1 19 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:r/m (w)","ModRM:reg (r)","ib","","Tuple2","Extract 128 bits of packed double precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1."
"VEXTRACTI32X8 ymm/m256{k}{z},zmm,ib","EVEX.512.66.0F3A.W0 3b /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:r/m (w)","ModRM:reg (r)","ib","","Tuple8","Extract 256 bits of double-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1."
"VEXTRACTI64X2 xmm/m128{k}{z},ymm,ib","EVEX.256.66.0F3A.W1 39 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:r/m (w)","ModRM:reg (r)","ib","","Tuple2","Extract 128 bits of quad-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1."
"VEXTRACTI64X2 xmm/m128{k}{z},zmm,ib","EVEX.512.66.0F3A.W1 39 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:r/m (w)","ModRM:reg (r)","ib","","Tuple2","Extract 128 bits of quad-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1."
"VFPCLASSPD k2 {k1}, xmm2/m128/m64bcst, ib","EVEX.128.66.0F3A.W1 66 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Full Vector","Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result."
"VFPCLASSPD k2 {k1}, ymm2/m256/m64bcst, ib","EVEX.256.66.0F3A.W1 66 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Full Vector","Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result."
"VFPCLASSPD k2 {k1}, zmm2/m512/m64bcst, ib","EVEX.512.66.0F3A.W1 66 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Full Vector","Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result."
"VFPCLASSPS k2 {k1}, xmm2/m128/m32bcst, ib","EVEX.128.66.0F3A.W0 66 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Full Vector","Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result."
"VFPCLASSPS k2 {k1}, ymm2/m256/m32bcst, ib","EVEX.256.66.0F3A.W0 66 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Full Vector","Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result."
"VFPCLASSPS k2 {k1}, zmm2/m512/m32bcst, ib","EVEX.512.66.0F3A.W0 66 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Full Vector","Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result."
"VFPCLASSSD k2 {k1}, xmm2/m64, ib","EVEX.LIG.66.0F3A.W1 67 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Tuple1 Scalar","Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result."
"VFPCLASSSS k2 {k1}, xmm2/m32, ib","EVEX.LIG.66.0F3A.W0 67 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Tuple1 Scalar","Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result."
"VINSERTF32X8 zmm{k}{z},zmm,ymm/m256,ib","EVEX.512.66.0F3A.W0 1a /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Tuple8","nsert 128 bits of packed double precision floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1."
"VINSERTF64X2 ymm{k}{z},ymm,xmm/m128,ib","EVEX.256.66.0F3A.W1 18 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Tuple2","Insert 128 bits of packed double precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1."
"VINSERTF64X2 zmm{k}{z},zmm,xmm/m128,ib","EVEX.512.66.0F3A.W1 18 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Tuple2","Insert 256 bits of packed single-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1."
"VINSERTI32X8 zmm{k}{z},zmm,ymm/m256,ib","EVEX.512.66.0F3A.W0 3a /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Tuple8","Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from ymm2 into ymm1 under writemask k1."
"VINSERTI64X2 ymm{k}{z},ymm,xmm/m128,ib","EVEX.256.66.0F3A.W1 38 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Tuple2","Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1."
"VINSERTI64X2 zmm{k}{z},zmm,xmm/m128,ib","EVEX.512.66.0F3A.W1 38 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Tuple2","Insert 256 bits of packed doubleword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1."
"VORPD xmm1{k1}{z}, xmm2, xmm3/m128/m64bcst","EVEX.128.66.0F.W1 56 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical OR of packed double-precision floating-point values in xmm2 and xmm3/m128/m64bcst subject to writemask k1."
"VORPD ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst","EVEX.256.66.0F.W1 56 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical OR of packed double-precision floating-point values in ymm2 and ymm3/m256/m64bcst subject to writemask k1."
"VORPD zmm1{k1}{z}, zmm2, zmm3/m512/m64bcst","EVEX.512.66.0F.W1 56 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical OR of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1."
"VORPS xmm1{k1}{z}, xmm2, xmm3/m128/m32bcst","EVEX.128.0F.W0 56 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical OR of packed single-precision floating-point values in xmm2 and xmm3/m128/m32bcst subject to writemask k1."
"VORPS ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst","EVEX.256.0F.W0 56 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical OR of packed single-precision floating-point values in ymm2 and ymm3/m256/m32bcst subject to writemask k1."
"VORPS zmm1{k1}{z}, zmm2, zmm3/m512/m32bcst","EVEX.512.0F.W0 56 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical OR of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1."
"VPEXTRD r32/m32, xmm2, ib","EVEX.128.66.0F3A.W0 16 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:r/m (w)","ModRM:reg (r)","ib","","Tuple1 Scalar","Extract a dword integer value from xmm2 at the source dword offset specified by ib into r/m."
"VPEXTRQ r64/m64, xmm2, ib","EVEX.128.66.0F3A.W1 16 /r ib","Valid","Invalid","Invalid","AVX512DQ","ModRM:r/m (w)","ModRM:reg (r)","ib","","Tuple1 Scalar","Extract a qword integer value from xmm2 at the source dword offset specified by ib into r/m."
"VPINSRD xmm1, xmm2, r32/m32, ib","EVEX.128.66.0F3A.W0 22 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Tuple1 Scalar","Insert a dword integer value from r/m32 and rest from xmm2 into xmm1 at the dword offset in ib."
"VPINSRQ xmm1, xmm2, r64/m64, ib","EVEX.128.66.0F3A.W1 22 /r ib","Valid","Invalid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Tuple1 Scalar","Insert a qword integer value from r/m64 and rest from xmm2 into xmm1 at the qword offset in ib."
"VPMOVD2M k1, xmm1","EVEX.128.F3.0F38.W0 39 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","","Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in XMM1."
"VPMOVD2M k1, ymm1","EVEX.256.F3.0F38.W0 39 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","","Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in YMM1."
"VPMOVD2M k1, zmm1","EVEX.512.F3.0F38.W0 39 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","","Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in ZMM1."
"VPMOVM2D xmm1, k1","EVEX.128.F3.0F38.W0 38 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","","Sets each doubleword in XMM1 to all 1's or all 0's based on the value of the corresponding bit in k1."
"VPMOVM2D ymm1, k1","EVEX.256.F3.0F38.W0 38 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","","Sets each doubleword in YMM1 to all 1's or all 0's based on the value of the corresponding bit in k1."
"VPMOVM2D zmm1, k1","EVEX.512.F3.0F38.W0 38 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","","Sets each doubleword in ZMM1 to all 1's or all 0's based on the value of the corresponding bit in k1."
"VPMOVM2Q xmm1, k1","EVEX.128.F3.0F38.W1 38 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","","Sets each quadword in XMM1 to all 1's or all 0's based on the value of the corresponding bit in k1."
"VPMOVM2Q ymm1, k1","EVEX.256.F3.0F38.W1 38 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","","Sets each quadword in YMM1 to all 1's or all 0's based on the value of the corresponding bit in k1."
"VPMOVM2Q zmm1, k1","EVEX.512.F3.0F38.W1 38 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","","Sets each quadword in ZMM1 to all 1's or all 0's based on the value of the corresponding bit in k1."
"VPMOVQ2M k1, xmm1","EVEX.128.F3.0F38.W1 39 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","","Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in XMM1."
"VPMOVQ2M k1, ymm1","EVEX.256.F3.0F38.W1 39 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","","Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in YMM1."
"VPMOVQ2M k1, zmm1","EVEX.512.F3.0F38.W1 39 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","","","","Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in ZMM1."
"VPMULLQ xmm1{k1}{z}, xmm2, xmm3/m128/m64bcst","EVEX.128.66.0F38.W1 40 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Multiply the packed qword signed integers in xmm2 and xmm3/m128/m64bcst and store the low 64 bits of each product in xmm1 under writemask k1."
"VPMULLQ ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst","EVEX.256.66.0F38.W1 40 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Multiply the packed qword signed integers in ymm2 and ymm3/m256/m64bcst and store the low 64 bits of each product in ymm1 under writemask k1."
"VPMULLQ zmm1{k1}{z}, zmm2, zmm3/m512/m64bcst","EVEX.512.66.0F38.W1 40 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Multiply the packed qword signed integers in zmm2 and zmm3/m512/m64bcst and store the low 64 bits of each product in zmm1 under writemask k1."
"VRANGEPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst, ib","EVEX.128.66.0F3A.W1 50 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full Vector","Calculate two RANGE operation output value from 2 pairs of double-precision floating-point values in xmm2 and xmm3/m128/m32bcst, store the results to xmm1 under the writemask k1. ib specifies the comparison and sign of the range operation."
"VRANGEPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst, ib","EVEX.256.66.0F3A.W1 50 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full Vector","Calculate four RANGE operation output value from 4pairs of double-precision floating-point values in ymm2 and ymm3/m256/m32bcst, store the results to ymm1 under the writemask k1. ib specifies the comparison and sign of the range operation."
"VRANGEPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst{sae}, ib","EVEX.512.66.0F3A.W1 50 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full Vector","Calculate eight RANGE operation output value from 8 pairs of double-precision floating-point values in zmm2 and zmm3/m512/m32bcst, store the results to zmm1 under the writemask k1. ib specifies the comparison and sign of the range operation."
"VRANGEPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst, ib","EVEX.128.66.0F3A.W0 50 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full Vector","Calculate four RANGE operation output value from 4 pairs of single-precision floating-point values in xmm2 and xmm3/m128/m32bcst, store the results to xmm1 under the writemask k1. ib specifies the comparison and sign of the range operation."
"VRANGEPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst, ib","EVEX.256.66.0F3A.W0 50 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full Vector","Calculate eight RANGE operation output value from 8 pairs of single-precision floating-point values in ymm2 and ymm3/m256/m32bcst, store the results to ymm1 under the writemask k1. ib specifies the comparison and sign of the range operation."
"VRANGEPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst{sae}, ib","EVEX.512.66.0F3A.W0 50 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full Vector","Calculate 16 RANGE operation output value from 16 pairs of single-precision floating-point values in zmm2 and zmm3/m512/m32bcst, store the results to zmm1 under the writemask k1. ib specifies the comparison and sign of the range operation."
"VRANGESD xmm1 {k1}{z}, xmm2, xmm3/m64{sae}, ib","EVEX.LIG.66.0F3A.W1 51 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Tuple1 Scalar","Calculate a RANGE operation output value from 2 double-precision floating-point values in xmm2 and xmm3/m64, store the output to xmm1 under writemask. ib specifies the comparison and sign of the range operation."
"VRANGESS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, ib","EVEX.LIG.66.0F3A.W0 51 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Tuple1 Scalar","Calculate a RANGE operation output value from 2 single-precision floating-point values in xmm2 and xmm3/m32, store the output to xmm1 under writemask. ib specifies the comparison and sign of the range operation."
"VREDUCEPD xmm1 {k1}{z}, xmm2/m128/m64bcst, ib","EVEX.128.66.0F3A.W1 56 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Full Vector","Perform reduction transformation on packed double-precision floating point values in xmm2/m128/m32bcst by subtracting a number of fraction bits specified by the ib field. Stores the result in xmm1 register under writemask k1."
"VREDUCEPD ymm1 {k1}{z}, ymm2/m256/m64bcst, ib","EVEX.256.66.0F3A.W1 56 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Full Vector","Perform reduction transformation on packed double-precision floating point values in ymm2/m256/m32bcst by subtracting a number of fraction bits specified by the ib field. Stores the result in ymm1 register under writemask k1."
"VREDUCEPD zmm1 {k1}{z}, zmm2/m512/m64bcst{sae}, ib","EVEX.512.66.0F3A.W1 56 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Full Vector","Perform reduction transformation on double-precision floating point values in zmm2/m512/m32bcst by subtracting a number of fraction bits specified by the ib field. Stores the result in zmm1 register under writemask k1."
"VREDUCEPS xmm1 {k1}{z}, xmm2/m128/m32bcst, ib","EVEX.128.66.0F3A.W0 56 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Full Vector","Perform reduction transformation on packed single-precision floating point values in xmm2/m128/m32bcst by subtracting a number of fraction bits specified by the ib field. Stores the result in xmm1 register under writemask k1."
"VREDUCEPS ymm1 {k1}{z}, ymm2/m256/m32bcst, ib","EVEX.256.66.0F3A.W0 56 /r ib","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Full Vector","Perform reduction transformation on packed single-precision floating point values in ymm2/m256/m32bcst by subtracting a number of fraction bits specified by the ib field. Stores the result in ymm1 register under writemask k1."
"VREDUCEPS zmm1 {k1}{z}, zmm2/m512/m32bcst{sae}, ib","EVEX.512.66.0F3A.W0 56 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","ModRM:r/m (r)","ib","","Full Vector","Perform reduction transformation on packed single-precision floating point values in zmm2/m512/m32bcst by subtracting a number of fraction bits specified by the ib field. Stores the result in zmm1 register under writemask k1."
"VREDUCESS xmm1 {k1}{z}, xmm2, xmm3/m32{sae}, ib","EVEX.LIG.66.0F3A.W0 57 /r ib","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Tuple1 Scalar","Perform a reduction transformation on a scalar single-precision floating point value in xmm3/m32 by subtracting a number of fraction bits specified by the ib field. Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32]. Stores the result in xmm1 register."
"VXORPD xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst","EVEX.128.66.0F.W1 57 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical XOR of packed double-precision floating-point values in xmm2 and xmm3/m128/m64bcst subject to writemask k1."
"VXORPD ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst","EVEX.256.66.0F.W1 57 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical XOR of packed double-precision floating-point values in ymm2 and ymm3/m256/m64bcst subject to writemask k1."
"VXORPD zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst","EVEX.512.66.0F.W1 57 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical XOR of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1."
"VXORPS xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst","EVEX.128.0F.W0 57 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical XOR of packed single-precision floating-point values in xmm2 and xmm3/m128/m32bcst subject to writemask k1."
"VXORPS ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst","EVEX.256.0F.W0 57 /r","Valid","Valid","Invalid","AVX512VL AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical XOR of packed single-precision floating-point values in ymm2 and ymm3/m256/m32bcst subject to writemask k1."
"VXORPS zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst","EVEX.512.0F.W0 57 /r","Valid","Valid","Invalid","AVX512DQ","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Vector","Return the bitwise logical XOR of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1."
