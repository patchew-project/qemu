"Instruction","Opcode","Valid 64-bit","Valid 32-bit","Valid 16-bit","Feature Flags","Operand 1","Operand 2","Operand 3","Operand 4","Tuple Type","Description"
"VPCOMPRESSB m128/i8x16{k},xmm","EVEX.128.66.0F38.W0 63 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:r/m (w)","ModRM:reg (r)","","","Tuple1 Scalar","Compress up to 128 bits of packed byte values from xmm1 to m128 with writemask k1."
"VPCOMPRESSB m256/i8x32{k},ymm","EVEX.256.66.0F38.W0 63 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:r/m (w)","ModRM:reg (r)","","","Tuple1 Scalar","Compress up to 256 bits of packed byte values from ymm1 to m256 with writemask k1."
"VPCOMPRESSB m512/i8x64{k},zmm","EVEX.512.66.0F38.W0 63 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:r/m (w)","ModRM:reg (r)","","","Tuple1 Scalar","Compress up to 512 bits of packed byte values from zmm1 to m512 with writemask k1."
"VPCOMPRESSB xmm/i8x16{k}{z},xmm","EVEX.128.66.0F38.W0 63 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:r/m (w)","ModRM:reg (r)","","","","Compress up to 128 bits of packed byte values from xmm2 to xmm1 with writemask k1."
"VPCOMPRESSB ymm/i8x32{k}{z},ymm","EVEX.256.66.0F38.W0 63 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:r/m (w)","ModRM:reg (r)","","","","Compress up to 256 bits of packed byte values from ymm2 to ymm1 with writemask k1."
"VPCOMPRESSB zmm/i8x64{k}{z},zmm","EVEX.512.66.0F38.W0 63 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:r/m (w)","ModRM:reg (r)","","","","Compress up to 512 bits of packed byte values from zmm2 to zmm1 with writemask k1."
"VPCOMPRESSW m128/i16x8{k},xmm","EVEX.128.66.0F38.W1 63 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:r/m (w)","ModRM:reg (r)","","","Tuple1 Scalar","Compress up to 128 bits of packed word values from xmm1 to m128 with writemask k1."
"VPCOMPRESSW m256/i16x16{k},ymm","EVEX.256.66.0F38.W1 63 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:r/m (w)","ModRM:reg (r)","","","Tuple1 Scalar","Compress up to 256 bits of packed word values from ymm1 to m256 with writemask k1."
"VPCOMPRESSW m512/i16x32{k},zmm","EVEX.512.66.0F38.W1 63 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:r/m (w)","ModRM:reg (r)","","","Tuple1 Scalar","Compress up to 512 bits of packed word values from zmm1 to m512 with writemask k1."
"VPCOMPRESSW xmm/i16x8{k}{z},xmm","EVEX.128.66.0F38.W1 63 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:r/m (w)","ModRM:reg (r)","","","","Compress up to 128 bits of packed word values from xmm2 to xmm1 with writemask k1."
"VPCOMPRESSW ymm/i16x16{k}{z},ymm","EVEX.256.66.0F38.W1 63 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:r/m (w)","ModRM:reg (r)","","","","Compress up to 256 bits of packed word values from ymm2 to ymm1 with writemask k1."
"VPCOMPRESSW zmm/i16x32{k}{z},zmm","EVEX.512.66.0F38.W1 63 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:r/m (w)","ModRM:reg (r)","","","","Compress up to 512 bits of packed word values from zmm2 to zmm1 with writemask k1."
"VPEXPANDB xmm{k}{z},m128/i8x16","EVEX.128.66.0F38.W0 62 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple1 Scalar","Expands up to 128 bits of packed byte values from m128 to xmm1 with writemask k1."
"VPEXPANDB xmm{k}{z},xmm/i8x16","EVEX.128.66.0F38.W0 62 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","ModRM:r/m (r)","","","","Expands up to 128 bits of packed byte values from xmm2 to xmm1 with writemask k1."
"VPEXPANDB ymm{k}{z},m256/i8x32","EVEX.256.66.0F38.W0 62 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple1 Scalar","Expands up to 256 bits of packed byte values from m256 to ymm1 with writemask k1."
"VPEXPANDB ymm{k}{z},ymm/i8x32","EVEX.256.66.0F38.W0 62 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","ModRM:r/m (r)","","","","Expands up to 256 bits of packed byte values from ymm2 to ymm1 with writemask k1."
"VPEXPANDB zmm{k}{z},m512/i8x64","EVEX.512.66.0F38.W0 62 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple1 Scalar","Expands up to 512 bits of packed byte values from m512 to zmm1 with writemask k1."
"VPEXPANDB zmm{k}{z},zmm/i8x64","EVEX.512.66.0F38.W0 62 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (w)","ModRM:r/m (r)","","","","Expands up to 512 bits of packed byte values from zmm2 to zmm1 with writemask k1."
"VPEXPANDW xmm{k}{z},m128/i16x8","EVEX.128.66.0F38.W1 62 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple1 Scalar","Expands up to 128 bits of packed word values from m128 to xmm1 with writemask k1."
"VPEXPANDW xmm{k}{z},xmm/i16x8","EVEX.128.66.0F38.W1 62 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","ModRM:r/m (r)","","","","Expands up to 128 bits of packed word values from xmm2 to xmm1 with writemask k1."
"VPEXPANDW ymm{k}{z},m256/i16x16","EVEX.256.66.0F38.W1 62 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple1 Scalar","Expands up to 256 bits of packed word values from m256 to ymm1 with writemask k1."
"VPEXPANDW ymm{k}{z},ymm/i16x16","EVEX.256.66.0F38.W1 62 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","ModRM:r/m (r)","","","","Expands up to 256 bits of packed word values from ymm2 to ymm1 with writemask k1."
"VPEXPANDW zmm{k}{z},m512/i16x32","EVEX.512.66.0F38.W1 62 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (w)","ModRM:r/m (r)","","","Tuple1 Scalar","Expands up to 512 bits of packed word values from m512 to zmm1 with writemask k1."
"VPEXPANDW zmm{k}{z},zmm/i16x32","EVEX.512.66.0F38.W1 62 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (w)","ModRM:r/m (r)","","","","Expands up to 512 bits of packed word values from zmm2 to zmm1 with writemask k1."
"VPSHLDD xmm{k}{z},xmm,xmm/m128/m32bcst,ib","EVEX.128.66.0F3A.W0 71 /r ib","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full","Concatenate destination and source operands, extract result shifted to the left by constant value in imm8 into xmm1."
"VPSHLDD ymm{k}{z},ymm,ymm/m256/m32bcst,ib","EVEX.256.66.0F3A.W0 71 /r ib","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full","Concatenate destination and source operands, extract result shifted to the left by constant value in imm8 into ymm1."
"VPSHLDD zmm{k}{z},zmm,zmm/m512/m32bcst,ib","EVEX.512.66.0F3A.W0 71 /r ib","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full","Concatenate destination and source operands, extract result shifted to the left by constant value in imm8 into zmm1."
"VPSHLDQ xmm{k}{z},xmm,xmm/m128/m64bcst,ib","EVEX.128.66.0F3A.W1 71 /r ib","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full","Concatenate destination and source operands, extract result shifted to the left by constant value in imm8 into xmm1."
"VPSHLDQ ymm{k}{z},ymm,ymm/m256/m64bcst,ib","EVEX.256.66.0F3A.W1 71 /r ib","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full","Concatenate destination and source operands, extract result shifted to the left by constant value in imm8 into ymm1."
"VPSHLDQ zmm{k}{z},zmm,zmm/m512/m64bcst,ib","EVEX.512.66.0F3A.W1 71 /r ib","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full","Concatenate destination and source operands, extract result shifted to the left by constant value in imm8 into zmm1."
"VPSHLDVD xmm{k}{z},xmm,xmm/m128/m32bcst","EVEX.128.66.0F38.W0 71 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full","Concatenate xmm1 and xmm2, extract result shifted to the left by value in xmm3/m128 into xmm1."
"VPSHLDVD ymm{k}{z},ymm,ymm/m256/m32bcst","EVEX.256.66.0F38.W0 71 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full","Concatenate ymm1 and ymm2, extract result shifted to the left by value in xmm3/m256 into ymm1."
"VPSHLDVD zmm{k}{z},zmm,zmm/m512/m32bcst","EVEX.512.66.0F38.W0 71 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full","Concatenate zmm1 and zmm2, extract result shifted to the left by value in zmm3/m512 into zmm1."
"VPSHLDVQ xmm{k}{z},xmm,xmm/m128/m64bcst","EVEX.128.66.0F38.W1 71 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full","Concatenate xmm1 and xmm2, extract result shifted to the left by value in xmm3/m128 into xmm1."
"VPSHLDVQ ymm{k}{z},ymm,ymm/m256/m64bcst","EVEX.256.66.0F38.W1 71 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full","Concatenate ymm1 and ymm2, extract result shifted to the left by value in xmm3/m256 into ymm1."
"VPSHLDVQ zmm{k}{z},zmm,zmm/m512/m64bcst","EVEX.512.66.0F38.W1 71 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full","Concatenate zmm1 and zmm2, extract result shifted to the left by value in zmm3/m512 into zmm1."
"VPSHLDVW xmm{k}{z},xmm,xmm/m128","EVEX.128.66.0F38.W1 70 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Mem","Concatenate xmm1 and xmm2, extract result shifted to the left by value in xmm3/m128 into xmm1."
"VPSHLDVW ymm{k}{z},ymm,ymm/m256","EVEX.256.66.0F38.W1 70 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Mem","Concatenate ymm1 and ymm2, extract result shifted to the left by value in xmm3/m256 into ymm1."
"VPSHLDVW zmm{k}{z},zmm,zmm/m512","EVEX.512.66.0F38.W1 70 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Mem","Concatenate zmm1 and zmm2, extract result shifted to the left by value in zmm3/m512 into zmm1."
"VPSHLDW xmm{k}{z},xmm,xmm/m128,ib","EVEX.128.66.0F3A.W1 70 /r ib","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full Mem","Concatenate destination and source operands, extract result shifted to the left by constant value in imm8 into xmm1."
"VPSHLDW ymm{k}{z},ymm,ymm/m256,ib","EVEX.256.66.0F3A.W1 70 /r ib","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full Mem","Concatenate destination and source operands, extract result shifted to the left by constant value in imm8 into ymm1."
"VPSHLDW zmm{k}{z},zmm,zmm/m512,ib","EVEX.512.66.0F3A.W1 70 /r ib","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full Mem","Concatenate destination and source operands, extract result shifted to the left by constant value in imm8 into zmm1."
"VPSHRDD xmm{k}{z},xmm,xmm/m128/m32bcst,ib","EVEX.128.66.0F3A.W0 73 /r ib","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full","Concatenate destination and source operands, extract result shifted to the right by constant value in imm8 into xmm1."
"VPSHRDD ymm{k}{z},ymm,ymm/m256/m32bcst,ib","EVEX.256.66.0F3A.W0 73 /r ib","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full","Concatenate destination and source operands, extract result shifted to the right by constant value in imm8 into ymm1."
"VPSHRDD zmm{k}{z},zmm,zmm/m512/m32bcst,ib","EVEX.512.66.0F3A.W0 73 /r ib","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full","Concatenate destination and source operands, extract result shifted to the right by constant value in imm8 into zmm1."
"VPSHRDQ xmm{k}{z},xmm,xmm/m128/m64bcst,ib","EVEX.128.66.0F3A.W1 73 /r ib","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full","Concatenate destination and source operands, extract result shifted to the right by constant value in imm8 into xmm1."
"VPSHRDQ ymm{k}{z},ymm,ymm/m256/m64bcst,ib","EVEX.256.66.0F3A.W1 73 /r ib","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full","Concatenate destination and source operands, extract result shifted to the right by constant value in imm8 into ymm1."
"VPSHRDQ zmm{k}{z},zmm,zmm/m512/m64bcst,ib","EVEX.512.66.0F3A.W1 73 /r ib","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full","Concatenate destination and source operands, extract result shifted to the right by constant value in imm8 into zmm1."
"VPSHRDVD xmm{k}{z},xmm,xmm/m128/m32bcst","EVEX.128.66.0F38.W0 73 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full","Concatenate xmm1 and xmm2, extract result shifted to the right by value in xmm3/m128 into xmm1."
"VPSHRDVD ymm{k}{z},ymm,ymm/m256/m32bcst","EVEX.256.66.0F38.W0 73 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full","Concatenate ymm1 and ymm2, extract result shifted to the right by value in xmm3/m256 into ymm1."
"VPSHRDVD zmm{k}{z},zmm,zmm/m512/m32bcst","EVEX.512.66.0F38.W0 73 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full","Concatenate zmm1 and zmm2, extract result shifted to the right by value in zmm3/m512 into zmm1."
"VPSHRDVQ xmm{k}{z},xmm,xmm/m128/m64bcst","EVEX.128.66.0F38.W1 73 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full","Concatenate xmm1 and xmm2, extract result shifted to the right by value in xmm3/m128 into xmm1."
"VPSHRDVQ ymm{k}{z},ymm,ymm/m256/m64bcst","EVEX.256.66.0F38.W1 73 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full","Concatenate ymm1 and ymm2, extract result shifted to the right by value in xmm3/m256 into ymm1."
"VPSHRDVQ zmm{k}{z},zmm,zmm/m512/m64bcst","EVEX.512.66.0F38.W1 73 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full","Concatenate zmm1 and zmm2, extract result shifted to the right by value in zmm3/m512 into zmm1."
"VPSHRDVW xmm{k}{z},xmm,xmm/m128","EVEX.128.66.0F38.W1 72 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Mem","Concatenate xmm1 and xmm2, extract result shifted to the right by value in xmm3/m128 into xmm1."
"VPSHRDVW ymm{k}{z},ymm,ymm/m256","EVEX.256.66.0F38.W1 72 /r","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Mem","Concatenate ymm1 and ymm2, extract result shifted to the right by value in xmm3/m256 into ymm1."
"VPSHRDVW zmm{k}{z},zmm,zmm/m512","EVEX.512.66.0F38.W1 72 /r","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (r, w)","EVEX.vvvv (r)","ModRM:r/m (r)","","Full Mem","Concatenate zmm1 and zmm2, extract result shifted to the right by value in zmm3/m512 into zmm1."
"VPSHRDW xmm{k}{z},xmm,xmm/m128,ib","EVEX.128.66.0F3A.W1 72 /r ib","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full Mem","Concatenate destination and source operands, extract result shifted to the right by constant value in imm8 into xmm1."
"VPSHRDW ymm{k}{z},ymm,ymm/m256,ib","EVEX.256.66.0F3A.W1 72 /r ib","Valid","Valid","Invalid","AVX512VL AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full Mem","Concatenate destination and source operands, extract result shifted to the right by constant value in imm8 into ymm1."
"VPSHRDW zmm{k}{z},zmm,zmm/m512,ib","EVEX.512.66.0F3A.W1 72 /r ib","Valid","Valid","Invalid","AVX512VBMI2","ModRM:reg (w)","EVEX.vvvv (r)","ModRM:r/m (r)","ib","Full Mem","Concatenate destination and source operands, extract result shifted to the right by constant value in imm8 into zmm1."
